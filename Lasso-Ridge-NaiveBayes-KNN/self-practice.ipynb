{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer, load_digits\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex    age  sibsp  parch      fare embarked\n",
       "0         1       1  female  29.00      0      0  211.3375        S\n",
       "1         1       1    male   0.92      1      2  151.5500        S\n",
       "2         0       1  female   2.00      1      2  151.5500        S\n",
       "3         0       1    male  30.00      1      2  151.5500        S\n",
       "4         0       1  female  25.00      1      2  151.5500        S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/User/Desktop/ML/lab3/titanic.csv')\n",
    "# removing name column\n",
    "data = data.drop(['name'], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.loc[:, 'pclass':], data['survived'],\n",
    "                                                    test_size=0.2, stratify=data['survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preprocessing\n",
    "NB can handle discrete features data which can be useful with categorical data.\n",
    "\n",
    "Let's see one of the advantages of NB classifier. NB is not affected by data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imputing missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit(x_train)\n",
    "x_train = pd.DataFrame(imputer.transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(imputer.transform(x_test), columns=x_test.columns)\n",
    "\n",
    "# one-hot-encode categorical features\n",
    "def ohe_new_features(df, features_name, encoder):\n",
    "    new_feats = encoder.transform(df[features_name])\n",
    "    # create dataframe from encoded features with named columns\n",
    "    new_cols = pd.DataFrame(new_feats, dtype=int, columns=encoder.get_feature_names_out(features_name))\n",
    "    new_df = pd.concat([df, new_cols], axis=1)\n",
    "    new_df.drop(features_name, axis=1, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "f_names = ['sex', 'embarked']\n",
    "encoder.fit(x_train[f_names])\n",
    "x_train = ohe_new_features(x_train, f_names, encoder)\n",
    "x_test = ohe_new_features(x_test, f_names, encoder)\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "scaled_x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n",
    "scaled_x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train and test two NB models ono the data before scaling and one after scaling\n",
    "and observe if the accuracy change with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before scaling: 0.7824427480916031\n",
      "Accuracy after scaling: 0.7824427480916031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# Write code here\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "print('Accuracy before scaling:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Write code here\n",
    "nb = GaussianNB()\n",
    "nb.fit(scaled_x_train, y_train)\n",
    "y_pred = nb.predict(scaled_x_test)\n",
    "print('Accuracy after scaling:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regularization\n",
    "What is [Elastic-Net](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net)?\n",
    "How can you specify the contribution of each part using l1 ration\n",
    "\n",
    "Apply classification on the breast cancer dataset with no regularization, l1,\n",
    "l2, and elastic-net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading Breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fitting both Lasso and Ridge\n",
    "\n",
    "Fit 3 models: Lasso and Ridge and Elastic-Net.\n",
    "Then print their accuracy and coefficients and notice the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso accuracy: 0.9064327485380117\n",
      "[[ 0.          0.          0.14588863  0.00514366  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.00358817  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.         -0.01990243\n",
      "   0.          0.          0.          0.          0.          0.        ]]\n",
      "Ridge accuracy: 0.9473684210526315\n",
      "[[ 1.09640017e-01  9.40354819e-03  2.41256569e-01 -1.48231133e-03\n",
      "  -1.88296821e-03 -1.26295292e-02 -1.78079619e-02 -7.44834423e-03\n",
      "  -2.87888883e-03 -3.55354677e-04  2.97699129e-03  2.63538923e-02\n",
      "  -2.23799180e-02 -3.38298211e-02 -2.21878805e-04 -2.67197044e-03\n",
      "  -3.76117018e-03 -1.03858123e-03 -6.79534888e-04 -2.01053761e-04\n",
      "   1.06196059e-01 -9.83823192e-02 -4.35472320e-02 -1.98145343e-02\n",
      "  -3.96628284e-03 -4.08350621e-02 -5.02097597e-02 -1.54695389e-02\n",
      "  -1.11331113e-02 -3.19995825e-03]]\n",
      "ElasticNet accuracy: 0.9181286549707602\n",
      "[[ 2.52526039e-03  4.67176470e-03  1.52643967e-02  1.22646301e-02\n",
      "   2.77916207e-05  6.66518857e-06 -1.93227381e-05 -9.99089349e-06\n",
      "   5.18166195e-05  2.10372816e-05  2.63404929e-05  3.63556875e-04\n",
      "   1.17252187e-04 -4.07215776e-03  2.22599037e-06  3.20013855e-06\n",
      "   3.19173402e-06  1.21347939e-06  6.12782604e-06  9.55234778e-07\n",
      "   2.53569662e-03  5.95213061e-03  1.51919149e-02 -1.30585508e-02\n",
      "   3.64147983e-05  5.81108195e-06 -2.74074356e-05 -6.93738413e-06\n",
      "   7.37706453e-05  2.34333590e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Write code here\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.01, random_state=123)\n",
    "ridge = LogisticRegression(penalty='l2', solver='liblinear', C=0.01, random_state=123)\n",
    "elasticnet = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.01, random_state=123)\n",
    "\n",
    "lasso.fit(x_train, y_train)\n",
    "ridge.fit(x_train, y_train)\n",
    "elasticnet.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lasso.predict(x_test)\n",
    "print('Lasso accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(lasso.coef_)\n",
    "\n",
    "y_pred = ridge.predict(x_test)\n",
    "print('Ridge accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(ridge.coef_)\n",
    "\n",
    "y_pred = elasticnet.predict(x_test)\n",
    "print('ElasticNet accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(elasticnet.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# KNN\n",
    "Compare KNN vs logistic regression\n",
    "\n",
    "---\n",
    "In ML images can be flattened to 1D vector of pixels, then we can train our\n",
    "models on them considering each pixel as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape (1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 1797 images flattened to 64-values vectors\n"
     ]
    }
   ],
   "source": [
    "# Based on https://github.com/hsu-ai-course/hsu.ai/blob/master/code/12.%20kNN%20and%20ANN%20for%20MNIST.ipynb\n",
    "digits = load_digits()\n",
    "\n",
    "print(\"Dataset shape\", digits.images.shape)\n",
    "\n",
    "# show first image\n",
    "plt.title(f\"Target: {digits.target[0]}\")\n",
    "plt.imshow(digits.images[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "print(\"Now we have {} images flattened to {}-values vectors\".format(*X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train a KNN and LR models and compare their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.97      0.97      0.97        35\n",
      "           2       1.00      0.97      0.99        36\n",
      "           3       0.91      1.00      0.95        29\n",
      "           4       1.00      0.97      0.98        30\n",
      "           5       0.95      0.97      0.96        40\n",
      "           6       1.00      1.00      1.00        44\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       1.00      0.90      0.95        39\n",
      "           9       0.98      0.98      0.98        41\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.97      0.97       360\n",
      "\n",
      "LR               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.92      0.97      0.94        35\n",
      "           2       0.97      0.97      0.97        36\n",
      "           3       0.97      1.00      0.98        29\n",
      "           4       0.97      0.97      0.97        30\n",
      "           5       0.97      0.93      0.95        40\n",
      "           6       1.00      0.98      0.99        44\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.97      0.92      0.95        39\n",
      "           9       0.93      0.98      0.95        41\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Write code here\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, knn.predict(X_test)\n",
    "print('KNN', classification_report(y_true, y_pred))\n",
    "\n",
    "y_true, y_pred = y_test, LR.predict(X_test)\n",
    "print('LR', classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Which model performed better? What is the advantages of each model over the other?\n",
    "\n",
    "What is the output of `classification_report` function? How to interpret it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
